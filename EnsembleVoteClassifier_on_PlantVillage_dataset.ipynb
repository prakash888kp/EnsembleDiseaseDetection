{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/prakash888kp/EnsembleDiseaseDetection/blob/main/EnsembleVoteClassifier_on_PlantVillage_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2raPD2bvt71"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "import os\n",
        "#By prakash(20MDS006)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2O4WAijePZu"
      },
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OADXYs4oPmdb",
        "outputId": "7ff0f719-8242-4771-beb4-09d64fd2a405"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xfQdJzTZxIvo"
      },
      "outputs": [],
      "source": [
        "data_dir = \"/content/drive/MyDrive/dataset/NewLeaf/PlantVillage-Dataset-master/raw/color\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orboAXHdefSv"
      },
      "source": [
        "### Import the all essential libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CfIpV-wTyTr0"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "import seaborn as sns\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import keras\n",
        "from numpy import load\n",
        "from matplotlib import pyplot\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras import backend\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPooling2D\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import load_img\n",
        "from keras.preprocessing.image import img_to_array\n",
        "from keras.layers import Dropout"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyTmqWELOkv4",
        "outputId": "68df193d-0d23-4220-d2c2-30328a8a69e7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: keras-tuner in /usr/local/lib/python3.7/dist-packages (1.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.21.6)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.8.0)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.0.4)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.1.1)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (3.0.8)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.6)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.44.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.35.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.6)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.2.4)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard->keras-tuner) (4.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.11.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (3.8.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard->keras-tuner) (4.2.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install keras-tuner"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnLsR7MAy9mx",
        "outputId": "e01761bc-88bb-486e-bfbf-e81ae9780fd0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n",
            "  after removing the cwd from sys.path.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from tensorflow.keras.models import Sequential,Model\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import MaxPool2D\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_UviqeTIeno-"
      },
      "source": [
        "## Image Processing and data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIYrPqHqzJuN"
      },
      "outputs": [],
      "source": [
        "batch_size = 32\n",
        "train_datagenerator = ImageDataGenerator(rescale = 1.0/255,\n",
        "                                        shear_range = 0.2,\n",
        "                                        zoom_range = 0.5,\n",
        "                                        horizontal_flip = True,\n",
        "                                        rotation_range=10,\n",
        "                                        width_shift_range=0.2,\n",
        "                                        brightness_range=[0.2,1.2],\n",
        "                                        validation_split = 0.2\n",
        "                                        )\n",
        "test_datagenerator = ImageDataGenerator(rescale = 1.0/255, validation_split=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PlQEwDA1zecM",
        "outputId": "bc3dd5d0-b3df-4f9d-c786-4633026ebc4b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 43456 images belonging to 38 classes.\n",
            "Found 10849 images belonging to 38 classes.\n"
          ]
        }
      ],
      "source": [
        "training_set = train_datagenerator.flow_from_directory(data_dir,\n",
        "                                                    target_size = (224,224),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                      subset= \"training\")\n",
        "\n",
        "valid_set = test_datagenerator.flow_from_directory(data_dir,\n",
        "                                                  target_size = (224,224),\n",
        "                                                    batch_size = 32,\n",
        "                                                    class_mode = 'categorical',\n",
        "                                                    subset= \"validation\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRMs0fBhvokM",
        "outputId": "6f0557d3-638e-4faf-9935-d08ef720ea2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Apple___Apple_scab': 0, 'Apple___Black_rot': 1, 'Apple___Cedar_apple_rust': 2, 'Apple___healthy': 3, 'Blueberry___healthy': 4, 'Cherry_(including_sour)___Powdery_mildew': 5, 'Cherry_(including_sour)___healthy': 6, 'Corn_(maize)___Cercospora_leaf_spot Gray_leaf_spot': 7, 'Corn_(maize)___Common_rust_': 8, 'Corn_(maize)___Northern_Leaf_Blight': 9, 'Corn_(maize)___healthy': 10, 'Grape___Black_rot': 11, 'Grape___Esca_(Black_Measles)': 12, 'Grape___Leaf_blight_(Isariopsis_Leaf_Spot)': 13, 'Grape___healthy': 14, 'Orange___Haunglongbing_(Citrus_greening)': 15, 'Peach___Bacterial_spot': 16, 'Peach___healthy': 17, 'Pepper,_bell___Bacterial_spot': 18, 'Pepper,_bell___healthy': 19, 'Potato___Early_blight': 20, 'Potato___Late_blight': 21, 'Potato___healthy': 22, 'Raspberry___healthy': 23, 'Soybean___healthy': 24, 'Squash___Powdery_mildew': 25, 'Strawberry___Leaf_scorch': 26, 'Strawberry___healthy': 27, 'Tomato___Bacterial_spot': 28, 'Tomato___Early_blight': 29, 'Tomato___Late_blight': 30, 'Tomato___Leaf_Mold': 31, 'Tomato___Septoria_leaf_spot': 32, 'Tomato___Spider_mites Two-spotted_spider_mite': 33, 'Tomato___Target_Spot': 34, 'Tomato___Tomato_Yellow_Leaf_Curl_Virus': 35, 'Tomato___Tomato_mosaic_virus': 36, 'Tomato___healthy': 37}\n"
          ]
        }
      ],
      "source": [
        "categories = list(training_set.class_indices.keys())\n",
        "print(training_set.class_indices)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TDY26O9k3xgw"
      },
      "source": [
        "Model_1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULdq5zsxQC2s",
        "outputId": "d0cad87b-c508-4508-f5b8-871738885de6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet/mobilenet_1_0_224_tf_no_top.h5\n",
            "17227776/17225924 [==============================] - 0s 0us/step\n",
            "17235968/17225924 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "base_model = tf.keras.applications.MobileNet(weights = \"imagenet\",\n",
        "                                             include_top = False,\n",
        "                                             input_shape = (224,224,3))\n",
        "\n",
        "inputs = keras.Input(shape = (224,224,3))\n",
        "\n",
        "x = base_model(inputs, training = False)\n",
        "x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
        "x = tf.keras.layers.Dropout(0.2)(x)\n",
        "x = tf.keras.layers.Dense(len(categories), activation=\"softmax\")(x)  # categories is 38 \n",
        "\n",
        "model = keras.Model(inputs = inputs, \n",
        "                    outputs = x, \n",
        "                    name=\"LeafDisease_model\")\n",
        "\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "\n",
        "model.compile(optimizer = optimizer,\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
        "                       'accuracy'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5dsnsiFx43H"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = optimizer,\n",
        "              loss = tf.keras.losses.CategoricalCrossentropy(from_logits = True),\n",
        "              metrics=[keras.metrics.CategoricalAccuracy(), \n",
        "                       'accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UAtsegMNx6Rp",
        "outputId": "cea52611-30e2-440a-fecd-dd8ad90cc9aa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/5\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py:1082: UserWarning: \"`categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a sigmoid or softmax activation and thus does not represent logits. Was this intended?\"\n",
            "  return dispatch_target(*args, **kwargs)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "50/50 [==============================] - 2315s 47s/step - loss: 2.9000 - categorical_accuracy: 0.2681 - accuracy: 0.2681 - val_loss: 1.6811 - val_categorical_accuracy: 0.5672 - val_accuracy: 0.5672\n",
            "Epoch 2/5\n",
            "50/50 [==============================] - 1844s 37s/step - loss: 1.6255 - categorical_accuracy: 0.5669 - accuracy: 0.5669 - val_loss: 1.0444 - val_categorical_accuracy: 0.7356 - val_accuracy: 0.7356\n",
            "Epoch 3/5\n",
            "50/50 [==============================] - 1490s 30s/step - loss: 1.2088 - categorical_accuracy: 0.6644 - accuracy: 0.6644 - val_loss: 0.7587 - val_categorical_accuracy: 0.8012 - val_accuracy: 0.8012\n",
            "Epoch 4/5\n",
            "50/50 [==============================] - 1210s 24s/step - loss: 0.9681 - categorical_accuracy: 0.7206 - accuracy: 0.7206 - val_loss: 0.6297 - val_categorical_accuracy: 0.8475 - val_accuracy: 0.8475\n",
            "Epoch 5/5\n",
            "50/50 [==============================] - 1074s 22s/step - loss: 0.8665 - categorical_accuracy: 0.7638 - accuracy: 0.7638 - val_loss: 0.5508 - val_categorical_accuracy: 0.8547 - val_accuracy: 0.8547\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(training_set,\n",
        "                    validation_data=valid_set,\n",
        "                    epochs=5,\n",
        "                    steps_per_epoch=50,\n",
        "                    validation_steps=50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bYzNEDt8yCjQ"
      },
      "outputs": [],
      "source": [
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epochs = range(len(loss))\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs,loss,c=\"red\",label=\"Training\")\n",
        "plt.plot(epochs,val_loss,c=\"blue\",label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sNkoBW9-zeUc"
      },
      "outputs": [],
      "source": [
        "acc = history.history['categorical_accuracy']\n",
        "val_acc = history.history['val_categorical_accuracy']\n",
        "\n",
        "epochs = range(len(acc))\n",
        "\n",
        "fig = plt.figure(figsize=(10,6))\n",
        "plt.plot(epochs,acc,c=\"red\",label=\"Training\")\n",
        "plt.plot(epochs,val_acc,c=\"blue\",label=\"Validation\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NRsoN69uXRjX"
      },
      "outputs": [],
      "source": [
        "model1.save(\"/content/drive/MyDrive/dataset/model1.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B735SfsX843C"
      },
      "source": [
        "# ** Model2**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tN44A_RLzd81"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "from tensorflow.keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.layers import Dense\n",
        "from glob import glob\n",
        "\n",
        "model2 = Sequential()\n",
        "model2.add(Conv2D(input_shape=(224,224,3),filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=64,kernel_size=(3,3),padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=128, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=256, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(Conv2D(filters=512, kernel_size=(3,3), padding=\"same\", activation=\"relu\"))\n",
        "model2.add(MaxPool2D(pool_size=(2,2),strides=(2,2)))\n",
        "model2.add(Flatten())\n",
        "model2.add(Dense(units=4096,activation=\"relu\"))\n",
        "model2.add(Dense(units=4096,activation=\"relu\"))\n",
        "model2.add(Dense(units=2, activation=\"softmax\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R1FnNvXBY6ee"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import Adam \n",
        "opt = Adam(lr=0.001)\n",
        "model2.compile(optimizer=opt, loss=keras.losses.categorical_crossentropy, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SViYHgfWZNB8"
      },
      "outputs": [],
      "source": [
        "model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IcMl4Zam9FZt"
      },
      "outputs": [],
      "source": [
        "classifier_model2=keras.models.Sequential()\n",
        "classifier_model2.add(model2)\n",
        "classifier_model2.add(Flatten())\n",
        "classifier_model2.add(Dense(38,activation='softmax'))\n",
        "classifier_model2.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wxRiOh7I9Usl"
      },
      "outputs": [],
      "source": [
        "classifier_model2.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jPyn453m9-NL"
      },
      "outputs": [],
      "source": [
        "train_num = training_set.samples\n",
        "valid_num = valid_set.samples\n",
        "print(\"train_num is:\",train_num)\n",
        "print(\"valid_num is:\",valid_num)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8OCHJ5gD9pu_"
      },
      "outputs": [],
      "source": [
        "history = classifier_model2.fit(training_set,\n",
        "                         steps_per_epoch=150,\n",
        "                         validation_data=valid_set,\n",
        "                         epochs=10,\n",
        "                         validation_steps=100,\n",
        "                         )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xfsse5_Y-NrO"
      },
      "outputs": [],
      "source": [
        "classifier_model2.save(\"/content/drive/MyDrive/dataset/model2.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "APEB7WlpD0j0"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "#accuracy plot\n",
        "plt.plot(epochs, acc, color='green', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#loss plot\n",
        "plt.plot(epochs, loss, color='pink', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, color='red', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "muDOfQ0dMWTY"
      },
      "source": [
        "# **Inception_V3 model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dy_s2WeUE27G"
      },
      "outputs": [],
      "source": [
        "# Import the inception model  \n",
        "from tensorflow.keras.applications.inception_v3 import InceptionV3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IzhxQbamIoRF"
      },
      "outputs": [],
      "source": [
        "model_inception = InceptionV3(input_shape = (224, 224, 3), # Shape of our images\n",
        "                                include_top = False, # Leave out the last fully connected layer\n",
        "                                weights = 'imagenet')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9b60YhA9I7xM"
      },
      "outputs": [],
      "source": [
        "for layer in model_inception.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OxCVBYswJO4b"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "# Flatten the output layer to 1 dimension\n",
        "x = layers.Flatten()(model_inception.output)\n",
        "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
        "x = layers.Dense(1024, activation='relu')(x)\n",
        "# Add a dropout rate of 0.2\n",
        "x = layers.Dropout(0.2)(x)                  \n",
        "# Add a final sigmoid layer for classification\n",
        "x = layers.Dense  (38, activation='sigmoid')(x)           \n",
        "\n",
        "model_inception = Model( model_inception.input, x) \n",
        "\n",
        "model_inception.compile(optimizer = RMSprop(learning_rate=0.0001), \n",
        "              loss = 'categorical_crossentropy', \n",
        "              metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ktdI1-z2JtZV"
      },
      "outputs": [],
      "source": [
        "history = model_inception.fit(training_set,\n",
        "                         steps_per_epoch=150,\n",
        "                         validation_data=valid_set,\n",
        "                         epochs=10,\n",
        "                         validation_steps=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Gty4WmBpJ-Yu"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "\n",
        "#accuracy plot\n",
        "plt.plot(epochs, acc, color='green', label='Training Accuracy')\n",
        "plt.plot(epochs, val_acc, color='blue', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend()\n",
        "\n",
        "plt.figure()\n",
        "#loss plot\n",
        "plt.plot(epochs, loss, color='pink', label='Training Loss')\n",
        "plt.plot(epochs, val_loss, color='red', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIMrgLj6Ozki"
      },
      "outputs": [],
      "source": [
        "model_inception.save(\"/content/drive/MyDrive/dataset/model3.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7JXPQ30O99A"
      },
      "outputs": [],
      "source": [
        "model1 = keras.models.load_model(\"/content/drive/MyDrive/dataset/model1.h5\")\n",
        "model2 = keras.models.load_model(\"/content/drive/MyDrive/dataset/model2.h5\")\n",
        "model3 = keras.models.load_model(\"/content/drive/MyDrive/dataset/model3.h5\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3x_TDsuXROXW"
      },
      "source": [
        "# **VotingEnsemble**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LotgYc5OXsJn"
      },
      "outputs": [],
      "source": [
        "class_dict = valid_set.class_indices\n",
        "li = list(class_dict.keys())\n",
        "print(li)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMg2mrkrf-Ih"
      },
      "source": [
        "Class votingClassifer without using an API"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nF0vFCDRt2t"
      },
      "outputs": [],
      "source": [
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "class votingClassifer:\n",
        "    'votingClassifer class'\n",
        "\n",
        "\n",
        "    def __init__(self, estimators,mode=\"hard\",weight=None,show_info=\"percent\"):\n",
        "        \n",
        "        if mode not in [\"hard\",\"soft\"]:\n",
        "            raise Exception(\"the mode should be 'hard' or 'soft'\")\n",
        "            \n",
        "        self.estimators=estimators\n",
        "        self.mode=mode\n",
        "        self.weight=weight\n",
        "        self.show_info=show_info  \n",
        "            \n",
        "    def predict(self,x_test):        \n",
        "        if self.mode==\"hard\":\n",
        "            return self.votingClassifer_hard(self.estimators, x_test, show_info=self.show_info)\n",
        "        else:\n",
        "            return self.votingClassifer_soft(self.estimators, x_test, weight=self.weight, show_info=self.show_info)\n",
        "\n",
        "    def getNumberDiff(self, index_classes, n):  \n",
        "        \n",
        "        for x in index_classes:\n",
        "            if index_class_prefer != x:\n",
        "                return x    \n",
        "    \n",
        "    def getNumberElse(self, index_classes, n):\n",
        "\n",
        "        indices = [i for i, value in enumerate(index_classes) if value != n]\n",
        "        counts = np.bincount(indices)\n",
        "        ind=np.argmax(counts)\n",
        "        n1=(indices == ind).sum()\n",
        " \n",
        "                \n",
        "        return n1\n",
        "    \n",
        "    \n",
        "    def votingClassifer_hard(self,estimators,x_test,show_info='percent'):\n",
        "        \n",
        "        if show_info not in [\"info\",\"percent\",\"nothing\"]:\n",
        "            raise Exception(\"the attribut 'show_info' should be 'info' or 'percent','nothing'\")            \n",
        "            \n",
        "        \n",
        "        cpt=0\n",
        "        index_classes_glob, class_names_glob, probs_glob=[],[],[]\n",
        "        N=len(x_test)\n",
        "        for x in x_test:\n",
        "            index_classes, class_names, probs=[],[],[]\n",
        "            for model in estimators:\n",
        "                img = np.expand_dims(x, axis=0)\n",
        "                # make a prediction\n",
        "                y_prob = model.predict(img)[0]\n",
        "                probabilty = y_prob.flatten()\n",
        "                max_prob = probabilty.max()\n",
        "                y_classes = y_prob.argmax(axis=-1)\n",
        "                index_class, class_name, prob = y_classes,[y_classes],max_prob\n",
        "                index_classes.append(index_class)\n",
        "                class_names.append(class_name)\n",
        "                probs.append(prob)\n",
        "            index_classes, class_names, probs = np.array(index_classes), np.array(class_names), np.array(probs)    \n",
        "            counts = np.bincount(index_classes)\n",
        "            index_class_prefer=np.argmax(counts)\n",
        " \n",
        "            n1=(index_classes == index_class_prefer).sum()\n",
        "    \n",
        "            if n1 == 1:\n",
        "                print(\"\\n Each estimator predict a different class\")\n",
        "                prob = probs.max()\n",
        "                indice = [i for i, value in enumerate(probs) if value == prob][0]\n",
        "                class_name = class_names[indice]\n",
        "\n",
        "                \n",
        "            elif n1 == len(estimators)/2 and len(estimators)/2 == self.getNumberElse(index_classes, index_class_prefer):\n",
        "                \n",
        "                print(\"\\n the half-estimators predict a class and the other estimators predict a different class\")\n",
        "                \n",
        "                indices1 = [i for i, value in enumerate(index_classes) if value == index_class_prefer]\n",
        "                sum2=0\n",
        "                for ind in indices1:\n",
        "                    sum2+=probs[ind]\n",
        "                \n",
        "                prob1=sum2/len(indices1)\n",
        "                \n",
        "                n2=self.getNumberDiff(index_classes, index_class_prefer)      \n",
        "                \n",
        "                indices2 = [i for i, value in enumerate(index_classes) if value == n2]\n",
        "                sum2=0\n",
        "                for ind in indices2:\n",
        "                    sum2+=probs[ind]\n",
        "                \n",
        "                prob2=sum2/len(indices2)\n",
        "                \n",
        "                if prob1 < prob2:\n",
        "                    prob=prob2\n",
        "                    indice = [i for i, value in enumerate(index_classes) if value == n2][0]\n",
        "                    class_name = class_names[indice]\n",
        "                    \n",
        "                else:\n",
        "                    prob=prob1\n",
        "                    indice = [i for i, value in enumerate(index_classes) if value == index_class_prefer][0]\n",
        "                    class_name = class_names[indice]\n",
        "                \n",
        "            else:\n",
        "                \n",
        "                sum1=0\n",
        "                nbr=0\n",
        "                for i, index in zip(range(len(probs)),index_classes):\n",
        "                    if index_class_prefer== index:\n",
        "                        sum1+=probs[i]\n",
        "                        nbr+=1\n",
        "                        \n",
        "                prob=sum1/nbr\n",
        "                indice = index_class_prefer\n",
        "                class_name = li[index_class_prefer]\n",
        "\n",
        "            \n",
        "            if show_info==\"info\":\n",
        "                cpt+=1\n",
        "                print(\"\\rpercent: {:.2f}%, li[{}]:{} --> {}\".format(cpt*100/N,index_class_prefer, li[index_class_prefer], prob), end='')   \n",
        "            elif show_info==\"percent\":\n",
        "                cpt+=1\n",
        "                print(\"\\rpercent: {:.2f}%\".format(cpt*100/N), end='')\n",
        "          \n",
        "                \n",
        "            index_classes_glob.append(indice)\n",
        "            class_names_glob.append(class_name)\n",
        "            probs_glob.append(prob)\n",
        "\n",
        "        return np.array(index_classes_glob), np.array(class_names_glob), np.array(probs_glob) \n",
        "    \n",
        "    \n",
        "    def votingClassifer_soft(self, estimators, x_test, weight=None, show_info=\"percent\"):\n",
        "        \n",
        "        if show_info not in [\"info\",\"percent\",\"nothing\"]:\n",
        "            raise Exception(\"the attribut 'show_info' should be 'info' or 'percent','nothing'\")  \n",
        "\n",
        "        if weight is None :\n",
        "            weight=np.ones(len(estimators))\n",
        "\n",
        "        if len(weight) != len(estimators):\n",
        "            raise Exception(\"number of models and wheight should be equals\")    \n",
        "\n",
        "        cpt=0 \n",
        "        # get number of classes \n",
        "        x = image.img_to_array(x_test[0])\n",
        "        x = np.expand_dims(x, axis=0)\n",
        "        y_prob = estimators[0].predict(x) \n",
        "        num_classes =  y_prob.shape[1]\n",
        "\n",
        "        Tab=np.zeros(num_classes)# num_classes\n",
        "        index_classes_glob, class_names_glob, probs_glob=[],[],[]\n",
        "        N=len(x_test)\n",
        "        for x in x_test:\n",
        "            index_classes, class_names, probs= [], [], []\n",
        "            for model in estimators:\n",
        "                img = np.expand_dims(x, axis=0)\n",
        "                # make a prediction\n",
        "                y_prob = model.predict(img)[0]\n",
        "                idxs = np.argsort(y_prob)\n",
        "                # loop over the indexes of the high confidence class labels\n",
        "                for (index, value) in enumerate(idxs):\n",
        "                    # build the label and draw the label on the image\n",
        "                    #label = \"{}) {}[{}]: {:.2f}%\".format(index,li[value],value, y_prob[value] * 100)\n",
        "                    #print(label)\n",
        "                    Tab[value]=y_prob[value]\n",
        "\n",
        "                probs.append(Tab)\n",
        "\n",
        "            probs=np.array(probs) # probs.shape: (3, 38)\n",
        "\n",
        "            proba=[]   \n",
        "\n",
        "            div=sum(weight)\n",
        "            for i in range(len(probs[0])):\n",
        "                s=0\n",
        "                for j in range(len(weight)):\n",
        "                    s+= probs[j][i] * weight[j] \n",
        "                s=s/div\n",
        "                proba.append(s)\n",
        "\n",
        "            proba=np.array(proba)\n",
        "            max_prob=max(proba)\n",
        "\n",
        "            indices=[i for i, value in enumerate(proba) if value == max_prob]\n",
        "\n",
        "            index_class, class_name, prob=indices[0],li[indices[0]],max_prob \n",
        "\n",
        "            index_classes_glob.append(index_class)\n",
        "            class_names_glob.append(class_name)\n",
        "            probs_glob.append(prob) \n",
        "\n",
        "            if show_info==\"info\":\n",
        "                cpt+=1\n",
        "                print(\"percent: {:.2f}%, li[{}]:{} --> {}%\".format(cpt*100/N,index_class, li[index_class], prob))   \n",
        "            elif show_info==\"percent\":\n",
        "                cpt+=1\n",
        "                print(\"\\rpercent: {:.2f}%\".format(cpt*100/N), end='')\n",
        "\n",
        "\n",
        "\n",
        "        return np.array(index_classes_glob), np.array(class_names_glob), np.array(probs_glob)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uio8ebqhTWWe"
      },
      "outputs": [],
      "source": [
        "x_test, y_test = valid_set.next()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qd4FBK5Vgk1M"
      },
      "source": [
        "Accuracy of each model on 1st set from test dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2pGmFA4OTcog"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "import numpy as np\n",
        "models=[MobileNet_model,Vgg16_model,inception_model]\n",
        "model_names=[\"MobileNet_model\",\"Vgg16_model\", \"inception_model\"]\n",
        "for model,model_name in zip(models,model_names):\n",
        "            \n",
        "    y_prob = model.predict(x_test)\n",
        "    y_pred1 = y_prob.argmax(axis=-1)\n",
        "    y_test1=np.argmax(y_test, axis=1)\n",
        "    # accuracy\n",
        "    print(model_name+\" accuracy: \",accuracy_score(y_test1,y_pred1))\n",
        "    del model , y_pred1, y_test1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nH_18fh8YNf8"
      },
      "source": [
        "**Accuracy** "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B76SdXpiUCCI"
      },
      "outputs": [],
      "source": [
        "y_test1=np.argmax(y_test, axis=1)\n",
        "y_pred1=index_classes\n",
        "\n",
        "# accuracy\n",
        "from sklearn.metrics import accuracy_score\n",
        "print(\"votingClassifer(hard) accuracy : \",accuracy_score(y_test1,y_pred1))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "15oQkEgxYWVc"
      },
      "source": [
        "## confusion_matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wv7LwxOuU8HL"
      },
      "outputs": [],
      "source": [
        "\n",
        "print(\"confusion_matrix\")\n",
        "from sklearn.metrics import classification_report, confusion_matrix,accuracy_score\n",
        "print(confusion_matrix(y_test1,y_pred1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7mfPmbyhh9Kq"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from sklearn.metrics import accuracy_score\n",
        "def getWeight(models):\n",
        "    tab=[]\n",
        "    cpt=0\n",
        "    nbr=len(models)\n",
        "    for model in models:\n",
        "        y_prob = model.predict(x_test)\n",
        "        y_pred1 = y_prob.argmax(axis=-1)\n",
        "        y_test1=np.argmax(y_test, axis=1)\n",
        "        tab.append(accuracy_score(y_test1,y_pred1))\n",
        "        cpt+=1\n",
        "        print(\"\\rpercent: {:.2f}%\".format(cpt*100/nbr), end='')\n",
        "        \n",
        "    tab=np.array(tab)    \n",
        "    max_value=max(tab) \n",
        "    weight=[(x*nbr/max_value) for x in tab]\n",
        "    weight=getmin_max_indice(np.array(weight))\n",
        "    return weight\n",
        "\n",
        "def getmin_max_indice(weight):\n",
        "    d=sorted(weight, reverse=True)\n",
        "    a=sorted(weight, reverse=False)\n",
        "    cpt=0\n",
        "    for ma,mi in zip(d,a):\n",
        "        max_indice=[i for i, value in enumerate(weight) if value == ma]\n",
        "        min_indice=[i for i, value in enumerate(weight) if value == mi]\n",
        "        c=weight[max_indice]\n",
        "        weight[max_indice]=weight[min_indice]\n",
        "        weight[min_indice]=c\n",
        "        cpt+=1\n",
        "        if cpt==int(len(weight)/2):\n",
        "            break\n",
        "    return weight\n",
        "\n",
        "models=[MobileNet_model,Vgg16_model,inception_model]\n",
        "weight=getWeight(models)\n",
        "print(\"\\nweight=\",weight)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u74VxqgUiQdy"
      },
      "source": [
        "## VotingClassifier(soft)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yibYu1PAh9By"
      },
      "outputs": [],
      "source": [
        "#VotingClassifier(soft)\n",
        "estimators = [MobileNet_model,Vgg16_model,inception_model]\n",
        "vc=votingClassifer(estimators=estimators,mode=\"soft\",weight=weight,show_info=\"percent\")\n",
        "\n",
        "index_classes, class_names, probs=vc.predict(x_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h-3L0Z_hZf1Y"
      },
      "outputs": [],
      "source": [
        "# predicting an image\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "directory= \"/tmp/PlantVillage-Dataset-master/raw/color/Apple___Apple_scab\"\n",
        "files = [os.path.join(directory,p) for p in sorted(os.listdir(directory))]\n",
        "\n",
        "models= [MobileNet_model,Vgg16_model,inception_model]\n",
        "model_names=[\"MobileNet_model\", \"Vgg16_model\", \"inception_model\"]\n",
        "for model,model_name in zip(models,model_names):\n",
        "    for i in range(0,3):\n",
        "        image_path = files[i]\n",
        "        new_img = image.load_img(image_path, target_size=(224, 224))\n",
        "        img = image.img_to_array(new_img)\n",
        "        img = np.expand_dims(img, axis=0)\n",
        "        img = img/255\n",
        "        prediction = model.predict(img)\n",
        "        probabilty = prediction.flatten()\n",
        "        max_prob = probabilty.max()\n",
        "        index=prediction.argmax(axis=-1)[0]\n",
        "        class_name = li[index]\n",
        "        #ploting image with predicted class name        \n",
        "        plt.figure(figsize = (4,4))\n",
        "        plt.imshow(new_img)\n",
        "        plt.axis('off')\n",
        "        plt.title(model_name+\": \"+class_name+\" \"+ str(max_prob)[0:4]+\"%\")\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tZqHeBBjjJWd"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.preprocessing import image\n",
        "import numpy as np\n",
        "directory= \"/tmp/PlantVillage-Dataset-master/raw/color/Apple___Apple_scab\"\n",
        "files = [os.path.join(directory,p) for p in sorted(os.listdir(directory))]\n",
        "\n",
        "for i in range(0,3):\n",
        "    image_path = files[i]\n",
        "    new_img = image.load_img(image_path, target_size=(224, 224))\n",
        "    img = image.img_to_array(new_img)\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    img = img/255\n",
        "    model_name=\"votingClassifer_soft\"\n",
        "    vc=votingClassifer(estimators=estimators,mode=\"soft\",weight=weight, show_info=\"nothing\")\n",
        "    index_classes, class_names, probs=vc.predict(img)\n",
        "    #ploting image with predicted class name        \n",
        "    plt.figure(figsize = (4,4))\n",
        "    plt.imshow(new_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(model_name+\": \"+class_names[0]+\" \"+str(probs[0])[0:4]+\"%\")\n",
        "    plt.show()\n",
        "    model_name=\"votingClassifer_hard\"\n",
        "    vc=votingClassifer(estimators=estimators,mode=\"hard\", show_info=\"nothing\")\n",
        "    index_classes, class_names, probs=vc.predict(img)    \n",
        "    #ploting image with predicted class name        \n",
        "    plt.figure(figsize = (4,4))\n",
        "    plt.imshow(new_img)\n",
        "    plt.axis('off')\n",
        "    plt.title(model_name+\": \"+class_names[0]+\" \"+str(probs[0])[0:4]+\"%\")\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nD5mVvbTjJOX"
      },
      "outputs": [],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M_CUXdhFa3G8"
      },
      "outputs": [],
      "source": [
        ""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "background_execution": "on",
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "EnsembleVoteClassifier_on_PlantVillage_dataset.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}